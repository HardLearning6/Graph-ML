{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HardLearning6/Graph-ML/blob/main/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **lab 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "### 实验目标\n",
        "\n",
        "1. 学习使用PYG进行数据集&数据处理\n",
        "2. 利用OGB数据集进行处理\n",
        "3. 利用OGB数据集来建立一个简单的GCN模型并进行验证\n",
        "4. 建立图神经网络GNN，并对OGB数据集进行属性预测\n",
        "\n",
        "### 实验说明\n",
        "\n",
        "1. 需要大家完成的任务是加粗且带有得分的题目，如 `问题 i：XXXXXXX（15分）`\n",
        "2. 做完实验后，请举手通知助教检查实验代码以及问题的输出结果，以便给同学们进行打分\n",
        "3. 如果大家有疑问尽量在实验课的前60分钟提出，后30分钟主要用于检查同学们的实验结果，可能时间没那么充裕\n",
        "\n",
        "### 参考文档：\n",
        "此处给出官方文档，同样推荐同学们去别的平台如stackoverflow等搜索\n",
        "1. NetworkX: https://networkx.org/documentation/stable/tutorial.html\n",
        "2. PyG ：https://pytorch-geometric.readthedocs.io/en/latest/\n",
        "3. OGB ：https://ogb.stanford.edu/\n",
        "\n",
        "\n",
        "我们将使用PyTorch Geometric（PyG）构建我们自己的图神经网络，并将模型应用于Open Graph Benchmark（OGB）数据集中的两个。 这两个数据集用于评估模型在两种不同的图相关任务上的表现。一个是节点属性预测，预测单个节点的属性。另一个是图属性预测，预测整个图或子图的属性。\n",
        "\n",
        "注意：确保按顺序运行每个部分中的所有单元格，这样中间变量/包就可以传递到下一个单元格。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGKqVEbbMEzf"
      },
      "source": [
        "\n",
        "# 设备\n",
        "+ 可选项：使用GPU加速（需要自己安装CUDA和torch-GPU版本）\n",
        "+ 使用CPU也可以，最长运行一个代码约5min左右"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0NiFL6OLpaJ"
      },
      "source": [
        "# 安装\n",
        "需要的库：\n",
        "1. torch-scatter\n",
        "2. torch-sparse\n",
        "3. torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By2oyBw7Lrh5",
        "outputId": "0f0d7c8a-9ca9-4d4f-c148-075aba5cacb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.4.0)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.4.26)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ],
      "source": [
        "# 注意下方安装库之前首先切换到自己的虚拟环境\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install ogb\n",
        "# 跑一次就行了，不用多次运行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1 PyG: 数据集&数据\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7vUmdNKCjA"
      },
      "source": [
        "PyTorch Geometric 通常有两个类用于将图结构存储或转换为张量格式。分别为torch_geometric.datasets与 torch_geometric.data，后者提供了将图数据处理为 PyTorch 张量的功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-o1P3r6hr2"
      },
      "source": [
        "## PyG 数据集\n",
        "\n",
        "torch_geometric.datasets 包含许多常见的图结构数据集。这里我们将通过一个示例数据集来学习它的使用方法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5qca3x6XpG",
        "outputId": "e377d729-02bf-442e-bff0-776947de7e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES(600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "root = './enzymes'  # 数据集的存储路径\n",
        "name = 'ENZYMES'    # 数据集名称\n",
        "\n",
        "# 加载 ENZYMES 数据集\n",
        "pyg_dataset = TUDataset('./enzymes', 'ENZYMES')\n",
        "\n",
        "# 打印数据集信息，可以发现该数据集中包含 600 个图\n",
        "print(pyg_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLm5vVYMAP2x"
      },
      "source": [
        "## 问题 1：ENZYMES 数据集中有多少个类别（classes）和多少个特征（features）？（20 分）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iF_Kyqr_JbY",
        "outputId": "b5a9aa95-2710-4d06-a18b-8df0910951ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES 数据集包含 6 个类别\n",
            "ENZYMES 数据集包含 3 个特征\n"
          ]
        }
      ],
      "source": [
        "def get_num_classes(pyg_dataset):\n",
        "  # TODO: 实现一个函数，接收一个 PyG 数据集对象，\n",
        "  # 并返回该数据集的类别数量。\n",
        "\n",
        "  num_classes = 0\n",
        "\n",
        "  ############# 在此处编写你的代码 ############\n",
        "  ## （约 1 行代码）lab2.ipynb\n",
        "\n",
        "  # TODO: 获取类别数量\n",
        "  return pyg_dataset.num_classes\n",
        "  #########################################\n",
        "\n",
        "  return num_classes\n",
        "\n",
        "def get_num_features(pyg_dataset):\n",
        "  # TODO: 实现一个函数，接收一个 PyG 数据集对象,并返回该数据集中每个节点的特征数量。\n",
        "\n",
        "  num_features = 0\n",
        "\n",
        "  ############# 在此处编写你的代码 ############\n",
        "  ## （约 1 行代码）\n",
        "  # TODO：获取特征数量\n",
        "  return pyg_dataset.num_features\n",
        "  #########################################\n",
        "\n",
        "  return num_features\n",
        "\n",
        "# 你可能会发现某些信息需要存储在数据集层级，\n",
        "# 特别是在数据集中包含多个图时。\n",
        "\n",
        "num_classes = get_num_classes(pyg_dataset)\n",
        "num_features = get_num_features(pyg_dataset)\n",
        "print(\"{} 数据集包含 {} 个类别\".format(name, num_classes))\n",
        "print(\"{} 数据集包含 {} 个特征\".format(name, num_features))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKbzhHUAckZ"
      },
      "source": [
        "## PyG Data\n",
        "\n",
        "每个 PyG 数据集通常存储的是一个 torch_geometric.data.Data 对象的列表。每个 Data 对象通常代表一个图。你可以通过索引数据集轻松获取某个具体的 Data 对象。\n",
        "\n",
        "\n",
        "参考官方文档：[Data 对象文档。](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sCV3xJWCddX"
      },
      "source": [
        "## 问题 2：ENZYMES 数据集中索引为 100 的图的标签是什么？（20 分）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIis9oTZAfs3",
        "outputId": "5e928250-3fac-43da-ba64-4c26fb073a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
            "索引为 100 的图的标签为 4\n"
          ]
        }
      ],
      "source": [
        "def get_graph_class(pyg_dataset, idx):\n",
        "  # TODO: 实现这个函数，接收一个 PyG 数据集对象、\n",
        "  # 图在数据集中的索引，返回该图的类别标签（整数）。\n",
        "\n",
        "  label = -1  # 默认标签为 -1\n",
        "\n",
        "  ############# 在此处编写你的代码 ############\n",
        "  ## （约 1 行代码）\n",
        "  # TODO：获取图标签\n",
        "  return int(pyg_dataset[idx].y)\n",
        "  #########################################\n",
        "\n",
        "  return label\n",
        "\n",
        "# 这里的 pyg_dataset 是用于图分类的数据集\n",
        "graph_0 = pyg_dataset[0]\n",
        "print(graph_0)  # 打印第一个图的信息\n",
        "\n",
        "idx = 100\n",
        "label = get_graph_class(pyg_dataset, idx)\n",
        "print('索引为 {} 的图的标签为 {}'.format(idx, label))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKhcVeAhCwoY"
      },
      "source": [
        "## 问题 3：ENZYMES 数据集中索引为 200 的图有多少条边？（20 分）\n",
        "\n",
        "在 PyG 中，图的边信息存储在 edge_index 中，它的形状是 [2, num_edges]。其中的每一列表示一条边的起点和终点。\n",
        "\n",
        "由于这是一个无向图，每条边通常会存储两次（即一次从 A→B，一次从 B→A），因此需要除以 2 得到真实的边数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5m2DOfhBtWv",
        "outputId": "dfbd843d-efd5-49bc-9dc6-3e1dfa50d9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "索引为 200 的图有 53 条边\n"
          ]
        }
      ],
      "source": [
        "def get_graph_num_edges(pyg_dataset, idx):\n",
        "  # TODO: 实现该函数，接收一个 PyG 数据集对象和图的索引，\n",
        "  # 返回该图中的边数（整数）。如果图是无向图，同一条边不能重复计数。\n",
        "  # 例如，在一个无向图 G 中，若节点 v 与 u 相连，该边只能计一次。\n",
        "\n",
        "  num_edges = 0  # 初始化边数为 0\n",
        "\n",
        "  ############# 在此处编写你的代码 ############\n",
        "  ## 注意：\n",
        "  ## 1. 不能直接返回 data.num_edges\n",
        "  ## 2. 假设图是无向的\n",
        "  ## （约 3-4 行代码）\n",
        "\n",
        "  # TODO：获取实际边数\n",
        "  data = pyg_dataset[idx]\n",
        "  edge_index = data.edge_index\n",
        "  num_edges = edge_index.size(1) // 2\n",
        "  #########################################\n",
        "\n",
        "  return num_edges\n",
        "\n",
        "# 获取索引为 200 的图的边数\n",
        "idx = 200\n",
        "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
        "print('索引为 {} 的图有 {} 条边'.format(idx, num_edges))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXa7yIG4E0Fp"
      },
      "source": [
        "# 2 Open Graph Benchmark (OGB)\n",
        "\n",
        "Open Graph Benchmark (OGB) 是一个用于图机器学习的现实、大规模且多样化的基准数据集集合。OGB 的数据集可以通过 OGB 数据加载器自动下载、处理和拆分。模型性能还可以通过 OGB 评估器以统一的方式进行评估。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnazPGGAJAZN"
      },
      "source": [
        "## 数据集和数据\n",
        "\n",
        "OGB 还支持 PyG 数据集和数据。这里我们将关注 ogbn-arxiv 数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpc6bTm3GF02",
        "outputId": "b8ea08db-6903-4c62-8507-ab8edd9cc7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:01<00:00, 78.95it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/arxiv.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting graphs into PyG objects...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3374.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n",
            "数据集 ogbn-arxiv 包含 1 个图\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/sparse.py:277: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj = torch.sparse_csr_tensor(\n"
          ]
        }
      ],
      "source": [
        "# 这里如果使用PYG2.6可能出现问题，需要手动指定DataTensorAttr，GlobalStorage安全性\n",
        "import torch\n",
        "from torch_geometric.data.data import DataTensorAttr\n",
        "from torch_geometric.data.storage import GlobalStorage\n",
        "from torch_geometric.data.data import DataEdgeAttr\n",
        "# 只添加错误消息中提到的类\n",
        "torch.serialization.add_safe_globals([\n",
        "    DataTensorAttr,\n",
        "    GlobalStorage\n",
        "])\n",
        "torch.serialization.add_safe_globals([DataEdgeAttr])\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "\n",
        "dataset_name = 'ogbn-arxiv'\n",
        "dataset = PygNodePropPredDataset(name=dataset_name, transform=T.ToSparseTensor())\n",
        "print('数据集 {} 包含 {} 个图'.format(dataset_name, len(dataset)))\n",
        "data = dataset[0]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw0xZJKZI-n3"
      },
      "source": [
        "## 问题 4：ogbn-arxiv 图中的特征数量是多少？（20 分）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP844_nT2ZJl",
        "outputId": "4e7bae31-2aac-42d2-9b94-aa810db522e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "该图包含 128 个特征\n"
          ]
        }
      ],
      "source": [
        "def graph_num_features(data):\n",
        "  # TODO: 实现此函数，接收一个 PyG 数据对象，获取节点特征维度\n",
        "  # 返回图中的特征数量（以整数表示）。\n",
        "\n",
        "  num_features = 0  # 初始化特征数量\n",
        "\n",
        "  ############# 在此处编写你的代码 ############\n",
        "  ## （约 1 行代码）\n",
        "  return data.x.shape[1]\n",
        "  #########################################\n",
        "\n",
        "  return num_features\n",
        "\n",
        "# 获取 ogbn-arxiv 图的特征数量\n",
        "num_features = graph_num_features(data)\n",
        "print('该图包含 {} 个特征'.format(num_features))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 3 GNN：节点属性预测\n",
        "\n",
        "\n",
        "在本节中，我们将使用 PyTorch Geometric 构建第一个图神经网络，并应用于节点属性预测（节点分类）。\n",
        "\n",
        "这里使用 GCN 运算符（[Kipf 等人 (2017)](https://arxiv.org/pdf/1609.02907.pdf)）来构建图神经网络。\n",
        "\n",
        "你应该直接使用 PyG 内置的 GCNConv 层。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CcOUEoInjD"
      },
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DCtgcHpGIpd",
        "outputId": "50d812a7-aed2-4964-ca1e-ae3cac1d35cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)  # 打印 PyTorch 的版本号\n",
        "\n",
        "# 使用 PyG 内置的 GCNConv 层\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# 导入 PyG 的转换模块\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "# 导入 OGB 数据集和评估器\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## 加载和预处理数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibJ0ieoIwQM",
        "outputId": "25f76fd8-d31d-4a40-9519-db4443eeb54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'ogbn-arxiv'  # 数据集名称\n",
        "# dataset = PygNodePropPredDataset(name=dataset_name,  # 创建PygNodePropPredDataset对象\n",
        "                                    # transform=T.ToSparseTensor())  # 将数据转换为稀疏张量\n",
        "\n",
        "# 使用 T.Compose 组合多个变换\n",
        "dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "                                 transform=T.Compose([\n",
        "                                     T.ToUndirected(),  # 转换为无向图（对称图）\n",
        "                                     T.ToSparseTensor()  # 转换为稀疏张量\n",
        "                                 ]))\n",
        "data = dataset[0]  # 获取数据集中的第一个数据\n",
        "\n",
        "# data.adj_t = data.adj_t.to_symmetric()  # 转换为对称矩阵\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # 判断是否有GPU，如果有则使用GPU\n",
        "\n",
        "# 如果使用GPU，设备应为cuda\n",
        "print('Device: {}'.format(device))  # 输出当前设备类型\n",
        "\n",
        "data = data.to(device)  # 将数据移动到指定的设备\n",
        "split_idx = dataset.get_idx_split()  # 获取数据集的索引划分\n",
        "train_idx = split_idx['train'].to(device)  # 将训练集索引移动到指定设备\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUA815bNJ8w"
      },
      "source": [
        "## GCN模型\n",
        "\n",
        "根据下图来实现GCN模型\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IgspXTYpNJLA"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds=False):\n",
        "        # 初始化函数，创建模型的各个层\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # A list of GCNConv layers\n",
        "        self.convs = None  # 用来存储GCN卷积层\n",
        "\n",
        "        # A list of 1D batch normalization layers\n",
        "        self.bns = None  # 用来存储BatchNorm1d层\n",
        "\n",
        "        # The log softmax layer\n",
        "        self.softmax = None  # 用来存储LogSoftmax层\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## 注意：\n",
        "        ## 1. self.convs 和 self.bns 应该使用 torch.nn.ModuleList 来实现\n",
        "        ## 2. self.convs 应包含 num_layers 个 GCNConv 层\n",
        "        ## 3. self.bns 应包含 num_layers - 1 个 BatchNorm1d 层\n",
        "        ## 4. self.softmax 使用 torch.nn.LogSoftmax\n",
        "        ## 5. GCNConv 的参数包括 'in_channels' 和 'out_channels'。更多信息请参考文档：\n",
        "        ##    https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
        "        ## 6. BatchNorm1d 的唯一参数是 'num_features'。更多信息请参考文档：\n",
        "        ##    https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
        "        ## (~10行代码)\n",
        "\n",
        "        def get_in_channels(idx):\n",
        "            return hidden_dim if idx > 0 else input_dim  # 获取每一层的输入通道数\n",
        "\n",
        "        def get_out_channels(idx):\n",
        "            return hidden_dim if idx < num_layers - 1 else output_dim  # 获取每一层的输出通道数\n",
        "\n",
        "        # 创建 GCNConv 和 BatchNorm1d 层\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            GCNConv(in_channels=get_in_channels(i), out_channels=get_out_channels(i))\n",
        "            for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.bns = torch.nn.ModuleList([\n",
        "            torch.nn.BatchNorm1d(num_features=get_out_channels(i))\n",
        "            for i in range(num_layers - 1)\n",
        "        ])\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=1)  # 使用LogSoftmax作为输出层\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        # dropout 的概率\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # 是否返回节点嵌入\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # 重置每个卷积层和批归一化层的参数\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        # 前向传播函数，接收特征张量x和邻接矩阵adj_t并返回输出\n",
        "\n",
        "        out = None\n",
        "\n",
        "        ############# Your code here ############\n",
        "        ## 注意：\n",
        "        ## 1. 按照图中的结构构建网络\n",
        "        ## 2. 使用 torch.nn.functional.relu 和 torch.nn.functional.dropout\n",
        "        ##    这两个函数非常有用。更多信息请参考文档：\n",
        "        ##    https://pytorch.org/docs/stable/nn.functional.html\n",
        "        ## 3. 不要忘记将 F.dropout 设置为训练模式\n",
        "        ## 4. 如果 return_embeds 为 True，则跳过最后的 softmax 层\n",
        "        ## (~7行代码)\n",
        "\n",
        "        # 前 num_layers-1 层使用卷积、批归一化、激活函数和dropout\n",
        "        for gcn, bn in zip(self.convs[:-1], self.bns):\n",
        "            x = gcn(x, adj_t)  # GCNConv 层\n",
        "            x = bn(x)  # 批归一化层\n",
        "            x = F.relu(x)  # 激活函数\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)  # dropout 层\n",
        "\n",
        "        # 最后一层只使用卷积层\n",
        "        out = self.convs[-1](x, adj_t)\n",
        "        if not self.return_embeds:\n",
        "            out = self.softmax(out)  # 使用 softmax 层\n",
        "\n",
        "        #########################################\n",
        "\n",
        "        return out  # 返回最终的输出\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FF1hnHUhO81e"
      },
      "outputs": [],
      "source": [
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.adj_t)\n",
        "\n",
        "    train_pred = out[train_idx]\n",
        "    train_y = data.y[train_idx].squeeze()\n",
        "\n",
        "    loss = loss_fn(train_pred, train_y)\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aJdlrJQhPBsK"
      },
      "outputs": [],
      "source": [
        "# 测试函数\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    # TODO: 实现这个函数，使用给定的split_idx和evaluator来测试模型\n",
        "    model.eval()\n",
        "\n",
        "    # 模型在所有数据上的输出\n",
        "    out = model(data.x, data.adj_t)\n",
        "\n",
        "    ############# 你的代码在这里 ############\n",
        "    ## (~1行代码)\n",
        "    ## 注意:\n",
        "    ## 1. 这里不要使用索引切片\n",
        "\n",
        "\n",
        "    #########################################\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7F46xkuLiOL",
        "outputId": "ab93bebb-9aa3-44ce-d71e-bb44da21bde8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'device': 'cuda',\n",
              " 'num_layers': 3,\n",
              " 'hidden_dim': 256,\n",
              " 'dropout': 0.5,\n",
              " 'lr': 0.01,\n",
              " 'epochs': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# 训练相关参数，epochs可以适度增加保证模型效率（但是会训练起来很慢！）\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 3,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100,\n",
        "}\n",
        "args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dT8RyM2cPGxM"
      },
      "outputs": [],
      "source": [
        "model = GCN(data.num_features, args['hidden_dim'],\n",
        "            dataset.num_classes, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd5O5cnPPdVF",
        "outputId": "101d2727-8353-4b80-f863-36693cddaa45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 4.0776, Train: 23.30%, Valid: 27.85% Test: 25.01%\n",
            "Epoch: 02, Loss: 2.3869, Train: 25.28%, Valid: 22.34% Test: 27.17%\n",
            "Epoch: 03, Loss: 1.9352, Train: 22.02%, Valid: 15.24% Test: 15.01%\n",
            "Epoch: 04, Loss: 1.7863, Train: 24.50%, Valid: 17.28% Test: 15.78%\n",
            "Epoch: 05, Loss: 1.6563, Train: 29.50%, Valid: 22.10% Test: 20.31%\n",
            "Epoch: 06, Loss: 1.5745, Train: 34.88%, Valid: 27.66% Test: 27.00%\n",
            "Epoch: 07, Loss: 1.5096, Train: 39.94%, Valid: 33.72% Test: 36.30%\n",
            "Epoch: 08, Loss: 1.4587, Train: 40.81%, Valid: 33.84% Test: 37.75%\n",
            "Epoch: 09, Loss: 1.4130, Train: 39.33%, Valid: 31.71% Test: 34.46%\n",
            "Epoch: 10, Loss: 1.3783, Train: 39.92%, Valid: 31.75% Test: 32.98%\n",
            "Epoch: 11, Loss: 1.3453, Train: 41.82%, Valid: 35.50% Test: 37.12%\n",
            "Epoch: 12, Loss: 1.3228, Train: 44.43%, Valid: 40.18% Test: 42.57%\n",
            "Epoch: 13, Loss: 1.2985, Train: 46.89%, Valid: 43.52% Test: 46.02%\n",
            "Epoch: 14, Loss: 1.2749, Train: 49.21%, Valid: 45.94% Test: 48.14%\n",
            "Epoch: 15, Loss: 1.2469, Train: 51.71%, Valid: 49.55% Test: 51.49%\n",
            "Epoch: 16, Loss: 1.2361, Train: 54.25%, Valid: 52.91% Test: 54.41%\n",
            "Epoch: 17, Loss: 1.2162, Train: 55.96%, Valid: 54.74% Test: 55.96%\n",
            "Epoch: 18, Loss: 1.1996, Train: 56.90%, Valid: 55.92% Test: 57.37%\n",
            "Epoch: 19, Loss: 1.1913, Train: 57.11%, Valid: 56.81% Test: 58.76%\n",
            "Epoch: 20, Loss: 1.1807, Train: 57.44%, Valid: 57.85% Test: 59.82%\n",
            "Epoch: 21, Loss: 1.1699, Train: 57.90%, Valid: 58.82% Test: 60.92%\n",
            "Epoch: 22, Loss: 1.1590, Train: 58.62%, Valid: 59.81% Test: 62.00%\n",
            "Epoch: 23, Loss: 1.1473, Train: 59.51%, Valid: 60.80% Test: 62.99%\n",
            "Epoch: 24, Loss: 1.1368, Train: 60.43%, Valid: 61.76% Test: 63.73%\n",
            "Epoch: 25, Loss: 1.1313, Train: 61.20%, Valid: 62.56% Test: 64.21%\n",
            "Epoch: 26, Loss: 1.1229, Train: 61.79%, Valid: 63.03% Test: 64.49%\n",
            "Epoch: 27, Loss: 1.1168, Train: 62.19%, Valid: 63.43% Test: 64.56%\n",
            "Epoch: 28, Loss: 1.1105, Train: 62.61%, Valid: 63.64% Test: 64.74%\n",
            "Epoch: 29, Loss: 1.1016, Train: 63.07%, Valid: 63.95% Test: 65.48%\n",
            "Epoch: 30, Loss: 1.0955, Train: 63.80%, Valid: 64.56% Test: 66.05%\n",
            "Epoch: 31, Loss: 1.0877, Train: 64.92%, Valid: 65.61% Test: 66.81%\n",
            "Epoch: 32, Loss: 1.0837, Train: 65.94%, Valid: 66.41% Test: 67.09%\n",
            "Epoch: 33, Loss: 1.0772, Train: 66.80%, Valid: 66.97% Test: 67.17%\n",
            "Epoch: 34, Loss: 1.0728, Train: 67.44%, Valid: 67.51% Test: 67.43%\n",
            "Epoch: 35, Loss: 1.0693, Train: 68.07%, Valid: 67.90% Test: 67.86%\n",
            "Epoch: 36, Loss: 1.0625, Train: 68.60%, Valid: 68.24% Test: 68.47%\n",
            "Epoch: 37, Loss: 1.0560, Train: 69.13%, Valid: 68.66% Test: 68.77%\n",
            "Epoch: 38, Loss: 1.0543, Train: 69.64%, Valid: 69.02% Test: 68.80%\n",
            "Epoch: 39, Loss: 1.0473, Train: 70.03%, Valid: 69.31% Test: 68.80%\n",
            "Epoch: 40, Loss: 1.0431, Train: 70.20%, Valid: 69.35% Test: 68.84%\n",
            "Epoch: 41, Loss: 1.0381, Train: 70.27%, Valid: 69.54% Test: 69.00%\n",
            "Epoch: 42, Loss: 1.0351, Train: 70.23%, Valid: 69.71% Test: 69.17%\n",
            "Epoch: 43, Loss: 1.0320, Train: 70.30%, Valid: 69.91% Test: 69.43%\n",
            "Epoch: 44, Loss: 1.0304, Train: 70.44%, Valid: 70.01% Test: 69.69%\n",
            "Epoch: 45, Loss: 1.0261, Train: 70.66%, Valid: 70.10% Test: 69.82%\n",
            "Epoch: 46, Loss: 1.0250, Train: 70.76%, Valid: 70.07% Test: 70.03%\n",
            "Epoch: 47, Loss: 1.0182, Train: 70.77%, Valid: 70.06% Test: 70.06%\n",
            "Epoch: 48, Loss: 1.0151, Train: 70.80%, Valid: 70.11% Test: 70.17%\n",
            "Epoch: 49, Loss: 1.0131, Train: 70.90%, Valid: 70.34% Test: 70.12%\n",
            "Epoch: 50, Loss: 1.0106, Train: 71.17%, Valid: 70.28% Test: 69.57%\n",
            "Epoch: 51, Loss: 1.0046, Train: 71.19%, Valid: 69.90% Test: 68.78%\n",
            "Epoch: 52, Loss: 1.0011, Train: 71.12%, Valid: 69.59% Test: 68.45%\n",
            "Epoch: 53, Loss: 1.0006, Train: 71.28%, Valid: 69.71% Test: 68.58%\n",
            "Epoch: 54, Loss: 1.0007, Train: 71.49%, Valid: 70.18% Test: 69.30%\n",
            "Epoch: 55, Loss: 0.9947, Train: 71.72%, Valid: 70.57% Test: 69.62%\n",
            "Epoch: 56, Loss: 0.9917, Train: 71.86%, Valid: 70.51% Test: 69.35%\n",
            "Epoch: 57, Loss: 0.9898, Train: 71.85%, Valid: 70.40% Test: 69.07%\n",
            "Epoch: 58, Loss: 0.9853, Train: 71.86%, Valid: 70.51% Test: 69.11%\n",
            "Epoch: 59, Loss: 0.9850, Train: 71.88%, Valid: 70.52% Test: 69.35%\n",
            "Epoch: 60, Loss: 0.9835, Train: 71.88%, Valid: 70.35% Test: 69.29%\n",
            "Epoch: 61, Loss: 0.9786, Train: 71.94%, Valid: 70.23% Test: 68.92%\n",
            "Epoch: 62, Loss: 0.9795, Train: 72.15%, Valid: 70.26% Test: 68.74%\n",
            "Epoch: 63, Loss: 0.9737, Train: 72.23%, Valid: 70.35% Test: 68.85%\n",
            "Epoch: 64, Loss: 0.9721, Train: 72.24%, Valid: 70.41% Test: 68.98%\n",
            "Epoch: 65, Loss: 0.9713, Train: 72.31%, Valid: 70.80% Test: 69.52%\n",
            "Epoch: 66, Loss: 0.9686, Train: 72.33%, Valid: 70.83% Test: 69.85%\n",
            "Epoch: 67, Loss: 0.9666, Train: 72.32%, Valid: 70.91% Test: 69.93%\n",
            "Epoch: 68, Loss: 0.9644, Train: 72.37%, Valid: 70.97% Test: 69.87%\n",
            "Epoch: 69, Loss: 0.9638, Train: 72.43%, Valid: 71.04% Test: 70.04%\n",
            "Epoch: 70, Loss: 0.9613, Train: 72.58%, Valid: 71.19% Test: 70.38%\n",
            "Epoch: 71, Loss: 0.9575, Train: 72.78%, Valid: 71.26% Test: 70.57%\n",
            "Epoch: 72, Loss: 0.9580, Train: 72.82%, Valid: 71.16% Test: 70.52%\n",
            "Epoch: 73, Loss: 0.9545, Train: 72.71%, Valid: 70.91% Test: 70.48%\n",
            "Epoch: 74, Loss: 0.9523, Train: 72.67%, Valid: 70.85% Test: 70.36%\n",
            "Epoch: 75, Loss: 0.9510, Train: 72.79%, Valid: 71.00% Test: 70.08%\n",
            "Epoch: 76, Loss: 0.9500, Train: 72.86%, Valid: 70.73% Test: 69.33%\n",
            "Epoch: 77, Loss: 0.9473, Train: 73.05%, Valid: 71.13% Test: 69.84%\n",
            "Epoch: 78, Loss: 0.9480, Train: 72.98%, Valid: 71.50% Test: 70.42%\n",
            "Epoch: 79, Loss: 0.9422, Train: 72.95%, Valid: 71.51% Test: 70.55%\n",
            "Epoch: 80, Loss: 0.9397, Train: 73.09%, Valid: 71.53% Test: 70.34%\n",
            "Epoch: 81, Loss: 0.9395, Train: 73.10%, Valid: 71.06% Test: 69.69%\n",
            "Epoch: 82, Loss: 0.9388, Train: 73.16%, Valid: 70.96% Test: 69.51%\n",
            "Epoch: 83, Loss: 0.9350, Train: 73.21%, Valid: 71.30% Test: 70.12%\n",
            "Epoch: 84, Loss: 0.9371, Train: 73.09%, Valid: 70.95% Test: 69.67%\n",
            "Epoch: 85, Loss: 0.9321, Train: 73.17%, Valid: 70.87% Test: 69.45%\n",
            "Epoch: 86, Loss: 0.9338, Train: 73.37%, Valid: 71.32% Test: 69.92%\n",
            "Epoch: 87, Loss: 0.9305, Train: 73.33%, Valid: 71.87% Test: 70.76%\n",
            "Epoch: 88, Loss: 0.9299, Train: 73.40%, Valid: 71.71% Test: 70.57%\n",
            "Epoch: 89, Loss: 0.9269, Train: 73.45%, Valid: 71.63% Test: 70.36%\n",
            "Epoch: 90, Loss: 0.9263, Train: 73.45%, Valid: 71.40% Test: 70.37%\n",
            "Epoch: 91, Loss: 0.9217, Train: 73.55%, Valid: 71.48% Test: 70.60%\n",
            "Epoch: 92, Loss: 0.9205, Train: 73.62%, Valid: 71.69% Test: 70.72%\n",
            "Epoch: 93, Loss: 0.9219, Train: 73.75%, Valid: 71.38% Test: 70.03%\n",
            "Epoch: 94, Loss: 0.9187, Train: 73.61%, Valid: 71.11% Test: 69.79%\n",
            "Epoch: 95, Loss: 0.9184, Train: 73.60%, Valid: 71.32% Test: 70.03%\n",
            "Epoch: 96, Loss: 0.9199, Train: 73.59%, Valid: 71.27% Test: 69.94%\n",
            "Epoch: 97, Loss: 0.9103, Train: 73.55%, Valid: 71.22% Test: 69.87%\n",
            "Epoch: 98, Loss: 0.9140, Train: 73.54%, Valid: 71.35% Test: 70.40%\n",
            "Epoch: 99, Loss: 0.9127, Train: 73.80%, Valid: 71.64% Test: 70.41%\n",
            "Epoch: 100, Loss: 0.9124, Train: 73.75%, Valid: 71.47% Test: 69.80%\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "# 重置参数来初始化随机值\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  loss = train(model, data, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, data, split_idx, evaluator)\n",
        "  train_acc, valid_acc, test_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}% '\n",
        "        f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqcextqOL2FX",
        "outputId": "f2335d36-285e-43c3-e69d-27ac41aff30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: Train: 73.33%, Valid: 71.87% Test: 70.76%\n"
          ]
        }
      ],
      "source": [
        "best_result = test(best_model, data, split_idx, evaluator)\n",
        "train_acc, valid_acc, test_acc = best_result\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}% '\n",
        "      f'Test: {100 * test_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMEg-olLjbJ"
      },
      "source": [
        "## 问题 5：你模型的验证集（validation）和测试集（test）上的最佳准确率是多少？ 请举手示意由助教检查. (20 points)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of CS224W - Colab 2.ipynb",
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}